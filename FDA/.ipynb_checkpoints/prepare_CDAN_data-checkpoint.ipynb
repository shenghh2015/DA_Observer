{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# dataset_folder = '/data/datasets'\n",
    "def load_source(train = 80000, valid = 400, test = 400, sig_rate = 0.035):\n",
    "# \ttrain = 80000\n",
    "# \tvalid = 400\n",
    "# \ttest = 400\n",
    "# \tsig_rate = 0.035\n",
    "    sig_file = '/shared/planck/Phantom/Breast_Xray/FDA_signals/hetero_sig.dat'\n",
    "    CLB_file = '/shared/rsaas/shenghua/CLB/CLB_128N_400000IM.npy'\n",
    "# \tsig_file = os.path.join(dataset_folder, 'FDA_signals/hetero_sig.dat')\n",
    "# \tCLB_file = os.path.join(dataset_folder, 'CLB/CLB_128N_400000IM.npy')\n",
    "    sig = np.fromfile(sig_file, dtype = np.float32).reshape(109,109)\n",
    "    data = np.load(CLB_file, mmap_mode='r')\n",
    "    X = data[:,:,0:train+valid+test]\n",
    "    X = np.transpose(np.reshape(X, [128, 128, train+valid+test], order='F'))\n",
    "    X_SA_trn, X_SA_val, X_SA_tst = X[:train, 64-54:64+55,64-54:64+55], X[train:train+valid, 64-54:64+55,64-54:64+55],\\\n",
    "        X[train+valid:train+valid+test, 64-54:64+55,64-54:64+55]\n",
    "    X_SP_trn, X_SP_val, X_SP_tst = X_SA_trn + sig * sig_rate, X_SA_val + sig * sig_rate, X_SA_tst + sig * sig_rate\n",
    "    X_trn, X_val, X_tst = np.concatenate([X_SA_trn, X_SP_trn]), np.concatenate([X_SA_val, X_SP_val]), np.concatenate([X_SA_tst, X_SP_tst])\n",
    "    y_trn = np.concatenate([np.zeros((train,1)), np.ones((train,1))]).flatten()\n",
    "    y_val = np.concatenate([np.zeros((valid,1)), np.ones((valid,1))]).flatten()\n",
    "    y_tst = np.concatenate([np.zeros((test,1)), np.ones((test,1))]).flatten()\n",
    "\n",
    "    return X_trn, X_val, X_tst, y_trn, y_val, y_tst\n",
    "\n",
    "def load_target(dataset = 'total', train = 80000, valid = 400, test = 400):\n",
    "# \tdataset = 'total'\n",
    "# \ttrain = 80000\n",
    "# \tvalid = 400\n",
    "# \ttest = 400\n",
    "# \tX_SA = np.load('/shared/planck/Phantom/Breast_Xray/FDA_DM_ROIs/npy_dataset/{}_SA.npy'.format(dataset))\n",
    "# \tX_SP = np.load('/shared/planck/Phantom/Breast_Xray/FDA_DM_ROIs/npy_dataset/{}_SP.npy'.format(dataset))\n",
    "    dataset_folder = '/shared/planck/Phantom/Breast_Xray/'\n",
    "    if dataset == 'dense':\n",
    "        offset_valid = 7100\n",
    "    elif dataset == 'hetero':\n",
    "        offset_valid = 36000\n",
    "    elif dataset == 'scattered':\n",
    "        offset_valid = 33000\n",
    "    elif dataset == 'fatty':\n",
    "        offset_valid = 9000\n",
    "    elif dataset == 'total':\n",
    "        offset_valid = 85000\n",
    "    offset_test = 400 + offset_valid\n",
    "    X_SA = np.load(os.path.join(dataset_folder, 'FDA_DM_ROIs/npy_dataset/{}_SA.npy'.format(dataset)))\n",
    "    X_SP = np.load(os.path.join(dataset_folder, 'FDA_DM_ROIs/npy_dataset/{}_SP.npy'.format(dataset)))\n",
    "    X_SA_trn, X_SA_val, X_SA_tst = X_SA[:train,:], X_SA[offset_valid:offset_valid+valid,:], X_SA[offset_test:offset_test+test,:]\n",
    "    X_SP_trn, X_SP_val, X_SP_tst = X_SP[:train,:], X_SP[offset_valid:offset_valid+valid,:], X_SP[offset_test:offset_test+test,:]\n",
    "    X_trn, X_val, X_tst = np.concatenate([X_SA_trn, X_SP_trn]), np.concatenate([X_SA_val, X_SP_val]), np.concatenate([X_SA_tst, X_SP_tst])\n",
    "    y_trn = np.concatenate([np.zeros((train,1)), np.ones((train,1))]).flatten()\n",
    "    y_val = np.concatenate([np.zeros((valid,1)), np.ones((valid,1))]).flatten()\n",
    "    y_tst = np.concatenate([np.zeros((test,1)), np.ones((test,1))]).flatten()\n",
    "    print('---- Dataset Summary: {} ----'.format(dataset))\n",
    "    print(' -all SA {}, SP {}'.format(X_SA.shape[0], X_SP.shape[0]))\n",
    "    print(' -trn SA {}, SP {}'.format(X_SA_trn.shape[0], X_SP_trn.shape[0]))\n",
    "    print(' -val SA {}, SP {}'.format(X_SA_val.shape[0], X_SP_val.shape[0]))\n",
    "    print(' -val SA {}, SP {}'.format(X_SA_tst.shape[0], X_SP_tst.shape[0]))\n",
    "    # \tprint('\\n')\n",
    "    return X_trn, X_val, X_tst, y_trn, y_val, y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source data\n",
    "noise = 2.0\n",
    "sig_rate = 0.035\n",
    "nb_source = 100\n",
    "Xs_trn, Xs_val, Xs_tst, ys_trn, ys_val, ys_tst = load_source(train = nb_source, sig_rate = sig_rate)\n",
    "Xs_trn, Xs_val, Xs_tst = np.random.RandomState(2).normal(Xs_trn, noise), np.random.RandomState(0).normal(Xs_val, noise), np.random.RandomState(1).normal(Xs_tst, noise)\n",
    "Xs_trn, Xs_val, Xs_tst = (Xs_trn-np.min(Xs_trn))/(np.max(Xs_trn)-np.min(Xs_trn)), (Xs_val-np.min(Xs_val))/(np.max(Xs_val)-np.min(Xs_val)), (Xs_tst-np.min(Xs_tst))/(np.max(Xs_tst)-np.min(Xs_tst))\n",
    "# load target data\n",
    "dataset = 'total'\n",
    "if dataset == 'dense':\n",
    "    nb_target = 7100\n",
    "elif dataset == 'hetero':\n",
    "    nb_target = 36000\n",
    "elif dataset == 'scattered':\n",
    "    nb_target = 33000\n",
    "elif dataset == 'fatty':\n",
    "    nb_target = 9000\n",
    "elif dataset == 'total':\n",
    "    nb_target = 100\n",
    "Xt_trn, Xt_val, Xt_tst, yt_trn, yt_val, yt_tst = load_target(dataset = dataset, train = nb_target, valid = 100)\n",
    "Xt_trn, Xt_val, Xt_tst = (Xt_trn-np.min(Xt_trn))/(np.max(Xt_trn)-np.min(Xt_trn)), (Xt_val-np.min(Xt_val))/(np.max(Xt_val)-np.min(Xt_val)), (Xt_tst-np.min(Xt_tst))/(np.max(Xt_tst)-np.min(Xt_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the folder\n",
    "def generate_folder(folder):\n",
    "    import os\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "dataset_folder = '/home/sh38/domain_adaptation/CDAN/data/clb-fda/'\n",
    "source_folder = dataset_folder+'clb/'; target_folder +'fda/'\n",
    "generate_folder(source_folder); generate_folder(target_folder)\n",
    "# Xs = np.concatenate([Xs_trn, Xs_val, Xs_tst]); ys  = np.concatenate([ys_trn, ys_val, ys_tst])\n",
    "# Xt = np.concatenate([Xt_trn, Xt_val, Xt_tst]); ys  = np.concatenate([yt_trn, yt_val, yt_tst])\n",
    "Xs = np.concatenate([Xs_trn, Xs_val]); ys  = np.concatenate([ys_trn, ys_val])\n",
    "Xt = np.concatenate([Xt_trn, Xt_val]); ys  = np.concatenate([yt_trn, yt_val])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(Xs.shape[0]):\n",
    "    image = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
